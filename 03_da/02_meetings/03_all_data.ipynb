{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collecting Vehicles' Dataset Shared Upon Meetings -- All Data**\n",
    "\n",
    "Simulation time computation is computationally really challenging. Therefore, we collect vehicle's dataset offline, after the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from multiprocessing.pool import Pool, ThreadPool\n",
    "from multiprocessing import Lock\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 1234, 1867, 613, 1001]\n",
    "TIME_LIMIT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_ROOT = \"../../02_data/01_simulation_results/\"\n",
    "VEH_LIST_PATH = \"../../02_data/veh_list.json\"\n",
    "MEETING_PATH = \"../../02_data/03_meeting_data/\"\n",
    "COMBINED_PATH = \"../../02_data/03_meeting_data/combined_dataset.csv\"\n",
    "EDGE_MAP_PATH = \"../../02_data/edge_maps.json\"\n",
    "NEIGHBORING_EDGES_FILE = \"../../02_data/neighboring_edges.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NEIGHBORING_EDGES_FILE) as f:\n",
    "    neighbors = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if not(os.path.exists(f\"{MEETING_PATH}/all_data\")):\n",
    "    os.makedirs(f\"{MEETING_PATH}/all_data\")\n",
    "for s in SEEDS:\n",
    "    if not(os.path.exists(f\"{MEETING_PATH}/all_data/{s}\")):\n",
    "        os.makedirs(f\"{MEETING_PATH}/all_data/{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading *test* vehicles:\n",
    "\n",
    "with open(VEH_LIST_PATH) as f:\n",
    "    veh_list  = json.load(f)\n",
    "\n",
    "test_vehicles = veh_list[\"test_vehs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_commuters(veh_id):\n",
    "    if veh_id.startswith(\"carIn\"):\n",
    "        return veh_id.split(\":\")[0]\n",
    "    return veh_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting meeting vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EDGE_MAP_PATH) as f:\n",
    "    edge_maps = json.load(f)\n",
    "\n",
    "edge_to_idx = edge_maps[\"edge_to_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading moving simulation data:\n",
    "\n",
    "m_data = pd.DataFrame()\n",
    "for s in SEEDS:\n",
    "    filename = f\"{RESULTS_ROOT}/vehicle_positions_{s}.csv\"\n",
    "    mf = pd.read_csv(filename)\n",
    "    mf[\"seed\"] = [s]*len(mf)\n",
    "    m_data = pd.concat([m_data, mf])\n",
    "\n",
    "m_data[\"veh_id\"] = m_data[\"veh_id\"].apply(combine_commuters)\n",
    "m_data = m_data[m_data[\"veh_id\"].isin(test_vehicles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_csv(COMBINED_PATH)\n",
    "whole_df[\"time\"] = whole_df[\"time\"].astype(int)\n",
    "whole_df[\"seed\"] = whole_df[\"seed\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = whole_df[whole_df[\"veh_id\"].isin(test_vehicles)]\n",
    "receive_time = [-1]*len(whole_df)\n",
    "whole_df[\"receive_time\"] = receive_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_meeting_vehicles_narrow(m_data, meeting_time, seed, meeting_times, meeting_time_gap=TIME_LIMIT):\n",
    "    #collecting recently met vehicles:\n",
    "    \n",
    "    meetings = m_data[m_data[\"time\"] == meeting_time]\n",
    "    meetings = meetings[meetings[\"seed\"] == seed]\n",
    "\n",
    "    mets = []\n",
    "\n",
    "    #same edges:\n",
    "    for edge in edge_to_idx:\n",
    "        vehs = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "        for i in range(len(vehs)):\n",
    "            for j in range(i+1, len(vehs)):\n",
    "                sender = vehs[i]\n",
    "                receiver = vehs[j]\n",
    "                #if not met yet or met long time ago:\n",
    "                if ((not((sender, receiver) in meeting_times)) or\n",
    "                    meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                    mets.append((sender, receiver))\n",
    "                    mets.append((receiver, sender)) #they meet vice-versa\n",
    "\n",
    "    #opposed edges:\n",
    "    for edge in edge_to_idx:\n",
    "        #only \"reversed\" edges are processed, to avoid duplicated meetings:\n",
    "        if edge.startswith(\"-\"):\n",
    "            veh_edge = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "            contra_edge = edge.split(\"-\")[1]\n",
    "            veh_contra = meetings[meetings[\"edge\"] == contra_edge][\"veh_id\"].unique()\n",
    "            for sender in veh_edge:\n",
    "                for receiver in veh_contra:\n",
    "                    #if not met yet or met long time ago:\n",
    "                    if ((not((sender, receiver) in meeting_times)) or\n",
    "                        meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                        mets.append((sender, receiver))\n",
    "                        mets.append((receiver, sender)) #they meet vice-versa\n",
    "\n",
    "\n",
    "    return mets #vehicles at the same time, at the same place, not the 'ego' vehicle and not met recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_meeting_vehicles_broad(m_data, meeting_time, seed, meeting_times, meeting_time_gap=TIME_LIMIT,\n",
    "                                   neighboring_edges = neighbors):\n",
    "    #collecting recently met vehicles:\n",
    "    \n",
    "    meetings = m_data[m_data[\"time\"] == meeting_time]\n",
    "    meetings = meetings[meetings[\"seed\"] == seed]\n",
    "\n",
    "    mets = []\n",
    "\n",
    "    #same edges:\n",
    "    for edge in edge_to_idx:\n",
    "        vehs = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "        for i in range(len(vehs)):\n",
    "            for j in range(i+1, len(vehs)):\n",
    "                sender = vehs[i]\n",
    "                receiver = vehs[j]\n",
    "                #if not met yet or met long time ago:\n",
    "                if ((not((sender, receiver) in meeting_times)) or\n",
    "                    meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                    mets.append((sender, receiver))\n",
    "                    mets.append((receiver, sender)) #they meet vice-versa\n",
    "\n",
    "    #other edges:\n",
    "    for edge in edge_to_idx:\n",
    "        for neigh in neighboring_edges[edge]:\n",
    "            veh_edge = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "            veh_contra = meetings[meetings[\"edge\"] == neigh][\"veh_id\"].unique()\n",
    "            for sender in veh_edge:\n",
    "                for receiver in veh_contra:\n",
    "                    #if not met yet or met long time ago:\n",
    "                    if ((not((sender, receiver) in meeting_times)) or\n",
    "                        meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                        mets.append((sender, receiver))\n",
    "                        mets.append((receiver, sender)) #they meet vice-versa\n",
    "\n",
    "\n",
    "    return mets #vehicles at the same time, at the same place, not the 'ego' vehicle and not met recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_upon_meeting(senders_data, meeting_time, seed, time_limit=TIME_LIMIT):\n",
    "    send_data = senders_data[senders_data[\"seed\"] == seed]\n",
    "    send_data = send_data[send_data[\"time\"] <= meeting_time]\n",
    "    send_data = send_data[send_data[\"time\"] >= meeting_time-time_limit]\n",
    "\n",
    "    \n",
    "    if not(\"receive_time\" in send_data.columns):\n",
    "        print(send_data)\n",
    "    return send_data.drop(columns=[\"receive_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_data(args):\n",
    "    sender, receiver, time, seed, vehicles_kb = args\n",
    "\n",
    "    received_data = collect_data_upon_meeting(vehicles_kb[sender], time, seed)\n",
    "\n",
    "    #storing shared data:\n",
    "    store_shared_data = {\n",
    "        \"sender\": sender,\n",
    "        \"receiver\": receiver,\n",
    "        \"time\": time,\n",
    "        \"data\": received_data.to_json()\n",
    "    }\n",
    "\n",
    "    #fusing data into the receiver vehicle's dataset:\n",
    "    rec_t = [time]*len(received_data)\n",
    "    received_data[\"receive_time\"] = rec_t\n",
    "\n",
    "    updated_kb = pd.concat([vehicles_kb[receiver], received_data], ignore_index=True)\n",
    "    updated_kb = updated_kb.drop_duplicates(subset=\"hash\", ignore_index=True)\n",
    "\n",
    "    return store_shared_data, updated_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_seed_script(seed):\n",
    "    p_data = whole_df[whole_df[\"seed\"] == seed]\n",
    "    meeting_times = {}\n",
    "    vehicles_kb = {}\n",
    "    store_sharing = []\n",
    "\n",
    "    for veh in test_vehicles:\n",
    "        vehicles_kb[veh] = copy.deepcopy(p_data[p_data[\"veh_id\"] == veh])\n",
    "\n",
    "    for t in trange(min(p_data[\"time\"]), max(p_data[\"time\"])):\n",
    "        meetings = collect_meeting_vehicles_broad(m_data, t, seed, meeting_times)\n",
    "        for sender, receiver in meetings:\n",
    "            arguments = [sender, receiver, t, seed, vehicles_kb]\n",
    "            meeting_times[(sender, receiver)] = t\n",
    "            \n",
    "            new_store, updated_kb = receive_data(arguments)\n",
    "            vehicles_kb[receiver] = copy.deepcopy(updated_kb)\n",
    "            store_sharing.append(new_store)\n",
    "\n",
    "    for veh in vehicles_kb:\n",
    "        vehicles_kb[veh].to_csv(f\"{MEETING_PATH}/all_data/{seed}/{veh}.csv\", index=False)\n",
    "    store_dict = {\n",
    "        \"shared_data\": store_sharing\n",
    "    }\n",
    "    with open(f\"{MEETING_PATH}/all_data/{seed}/shared_data.json\", \"w\") as f:\n",
    "        json.dump(store_dict, f)\n",
    "\n",
    "with Pool(5) as ps:\n",
    "    ps.map(per_seed_script, SEEDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
