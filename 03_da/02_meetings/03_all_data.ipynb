{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collecting Vehicles' Dataset Shared Upon Meetings -- All Data**\n",
    "\n",
    "Simulation time computation is computationally really challenging. Therefore, we collect vehicle's dataset offline, after the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from multiprocessing.pool import Pool, ThreadPool\n",
    "from multiprocessing import Lock\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 1234, 1867, 613, 1001]\n",
    "TIME_LIMIT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_ROOT = \"../../02_data/01_simulation_results/\"\n",
    "VEH_LIST_PATH = \"../../02_data/veh_list.json\"\n",
    "MEETING_PATH = \"../../02_data/03_meeting_data/\"\n",
    "COMBINED_PATH = \"../../02_data/03_meeting_data/combined_dataset.csv\"\n",
    "\n",
    "MEETING_VEHICLES = \"../../02_data/meeting_vehicles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if not(os.path.exists(f\"{MEETING_PATH}/all_data\")):\n",
    "    os.makedirs(f\"{MEETING_PATH}/all_data\")\n",
    "for s in SEEDS:\n",
    "    if not(os.path.exists(f\"{MEETING_PATH}/all_data/{s}\")):\n",
    "        os.makedirs(f\"{MEETING_PATH}/all_data/{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading *test* vehicles:\n",
    "\n",
    "with open(VEH_LIST_PATH) as f:\n",
    "    veh_list  = json.load(f)\n",
    "\n",
    "test_vehicles = veh_list[\"test_vehs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_commuters(veh_id):\n",
    "    if veh_id.startswith(\"carIn\"):\n",
    "        return veh_id.split(\":\")[0]\n",
    "    return veh_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_csv(COMBINED_PATH)\n",
    "whole_df[\"time\"] = whole_df[\"time\"].astype(int)\n",
    "whole_df[\"seed\"] = whole_df[\"seed\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = whole_df[whole_df[\"veh_id\"].isin(test_vehicles)]\n",
    "receive_time = [-1]*len(whole_df)\n",
    "whole_df[\"receive_time\"] = receive_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_upon_meeting(senders_data, meeting_time, seed, time_limit=TIME_LIMIT):\n",
    "    send_data = senders_data[senders_data[\"seed\"] == seed]\n",
    "    send_data = send_data[send_data[\"time\"] <= meeting_time]\n",
    "    send_data = send_data[send_data[\"time\"] >= meeting_time-time_limit]\n",
    "\n",
    "    \n",
    "    if not(\"receive_time\" in send_data.columns):\n",
    "        print(send_data)\n",
    "    return send_data.drop(columns=[\"receive_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_data(args):\n",
    "    sender, receiver, time, seed, vehicles_kb = args\n",
    "\n",
    "    received_data = collect_data_upon_meeting(vehicles_kb[sender], time, seed)\n",
    "\n",
    "    #storing shared data:\n",
    "    store_shared_data = {\n",
    "        \"sender\": sender,\n",
    "        \"receiver\": receiver,\n",
    "        \"time\": time,\n",
    "        \"data\": received_data.to_json()\n",
    "    }\n",
    "\n",
    "    #fusing data into the receiver vehicle's dataset:\n",
    "    rec_t = [time]*len(received_data)\n",
    "    received_data[\"receive_time\"] = rec_t\n",
    "\n",
    "    updated_kb = pd.concat([vehicles_kb[receiver], received_data], ignore_index=True)\n",
    "    updated_kb = updated_kb.drop_duplicates(subset=\"hash\", ignore_index=True)\n",
    "\n",
    "    return store_shared_data, updated_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_seed_script(args):\n",
    "    seed, meeting_collection_name = args\n",
    "    \n",
    "    with open(f\"{MEETING_VEHICLES}_{meeting_collection_name}_{seed}.json\") as f:\n",
    "        meetings = json.load(f)\n",
    "    \n",
    "    p_data = whole_df[whole_df[\"seed\"] == seed]\n",
    "    vehicles_kb = {}\n",
    "    store_sharing = []\n",
    "\n",
    "    for veh in test_vehicles:\n",
    "        vehicles_kb[veh] = copy.deepcopy(p_data[p_data[\"veh_id\"] == veh])\n",
    "\n",
    "    for t in trange(min(p_data[\"time\"]), max(p_data[\"time\"])):\n",
    "        if str(t) in meetings:\n",
    "            mets = meetings[str(t)]\n",
    "            for sender, receiver in mets:\n",
    "                arguments = [sender, receiver, t, seed, vehicles_kb]\n",
    "\n",
    "                new_store, updated_kb = receive_data(arguments)\n",
    "                vehicles_kb[receiver] = copy.deepcopy(updated_kb)\n",
    "                store_sharing.append(new_store)\n",
    "\n",
    "    for veh in vehicles_kb:\n",
    "        vehicles_kb[veh].to_csv(f\"{MEETING_PATH}/all_data/{seed}/{veh}.csv\", index=False)\n",
    "    store_dict = {\n",
    "        \"shared_data\": store_sharing\n",
    "    }\n",
    "    with open(f\"{MEETING_PATH}/all_data/{seed}/shared_data.json\", \"w\") as f:\n",
    "        json.dump(store_dict, f)\n",
    "\n",
    "with Pool(5) as ps:\n",
    "    ps.map(per_seed_script, zip(SEEDS, [\"broad\"]*5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
