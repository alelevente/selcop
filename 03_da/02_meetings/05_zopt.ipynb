{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sharing an Optimized Part of the Dataset**\n",
    "\n",
    "Alter's goal is to obtain the most possible information, while Ego aims to hide its path.\n",
    "\n",
    "The shared data, therefore, is an (optimal) deal between the two goals. However, making such deal is far from trivial.\n",
    "\n",
    "In this notebook, we implement an optimization strategy inspired by the well-known Zeuthen negotiation strategy. In this implementation, Ego will make the calculations, also considering the needs of Alter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"05_zopt_helpers\")\n",
    "import zopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 1234, 1867, 613, 1001]\n",
    "TIME_LIMIT = 300\n",
    "FALL_BACK_TIME = 15 #seconds -> corresponds to max. 208.3 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_ROOT = \"../../02_data/01_simulation_results/\"\n",
    "VEH_LIST_PATH = \"../../02_data/veh_list.json\"\n",
    "MEETING_PATH = \"../../02_data/03_meeting_data/\"\n",
    "COMBINED_PATH = \"../../02_data/03_meeting_data/combined_dataset.csv\"\n",
    "\n",
    "SOURCE_PROB_PATH = \"../../02_data/source_probs.json\"\n",
    "FORWARD_PROB_PATH = \"../../02_data/forward_probs.json\"\n",
    "PARKING_DEFINITION_FILE = \"../../01_simulation/02_scenario/parking_areas.add.xml\"\n",
    "\n",
    "MEETING_VEHICLES = \"../../02_data/meeting_vehicles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if not(os.path.exists(f\"{MEETING_PATH}/zopt\")):\n",
    "    os.makedirs(f\"{MEETING_PATH}/zopt\")\n",
    "for s in SEEDS:\n",
    "    if not(os.path.exists(f\"{MEETING_PATH}/zopt/{s}\")):\n",
    "        os.makedirs(f\"{MEETING_PATH}/zopt/{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading *test* vehicles:\n",
    "\n",
    "with open(VEH_LIST_PATH) as f:\n",
    "    veh_list  = json.load(f)\n",
    "\n",
    "test_vehicles = veh_list[\"test_vehs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = pd.read_csv(COMBINED_PATH)\n",
    "p_data[\"time\"] = p_data[\"time\"].astype(int)\n",
    "p_data = p_data[p_data[\"veh_id\"].isin(test_vehicles)]\n",
    "receive_time = [-1]*len(p_data)\n",
    "p_data[\"receive_time\"] = receive_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_commuters(veh_id):\n",
    "    if veh_id.startswith(\"carIn\"):\n",
    "        return veh_id.split(\":\")[0]\n",
    "    return veh_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SOURCE_PROB_PATH) as f:\n",
    "    source_probs = json.load(f)\n",
    "\n",
    "with open(FORWARD_PROB_PATH) as f:\n",
    "    forward_probs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_df = pd.read_xml(PARKING_DEFINITION_FILE, xpath=\"parkingArea\")\n",
    "parking_df = parking_df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_edges = []\n",
    "for _,r in parking_df.iterrows():\n",
    "    p_edges.append(r[\"lane\"].split(\"_\")[0])\n",
    "parking_df[\"edge\"] = p_edges\n",
    "\n",
    "meas_edge = []\n",
    "for _,r in p_data.iterrows():\n",
    "    meas_edge.append(parking_df.loc[r.parking_id].edge)\n",
    "p_data[\"edge\"] = meas_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_meeting_vehicles(m_data, meeting_time, seed, meeting_times, meeting_time_gap=TIME_LIMIT):\n",
    "    def create_meeting_dict(sender, receiver, direction, receiver_position):\n",
    "        return {\n",
    "            \"sender\": sender,\n",
    "            \"receiver\": receiver,\n",
    "            \"receiver_position\": receiver_position,\n",
    "            \"direction\": direction\n",
    "        }\n",
    "    \n",
    "    #collecting recently met vehicles:\n",
    "    meetings = m_data[m_data[\"time\"] == meeting_time]\n",
    "    meetings = meetings[meetings[\"seed\"] == seed]\n",
    "\n",
    "    mets = []\n",
    "\n",
    "    #same edges:\n",
    "    for edge in edge_to_idx:\n",
    "        vehs = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "        for i in range(len(vehs)):\n",
    "            for j in range(i+1, len(vehs)):\n",
    "                sender = vehs[i]\n",
    "                receiver = vehs[j]\n",
    "                #if not met yet or met long time ago:\n",
    "                if ((not((sender, receiver) in meeting_times)) or\n",
    "                    meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                    mets.append(create_meeting_dict(sender, receiver, \"same\", edge))\n",
    "                    mets.append(create_meeting_dict(receiver, sender, \"same\", edge)) #they meet vice-versa\n",
    "\n",
    "    #opposed edges:\n",
    "    for edge in edge_to_idx:\n",
    "        #only \"reversed\" edges are processed, to avoid duplicated meetings:\n",
    "        if edge.startswith(\"-\"):\n",
    "            veh_edge = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "            contra_edge = edge.split(\"-\")[1]\n",
    "            veh_contra = meetings[meetings[\"edge\"] == contra_edge][\"veh_id\"].unique()\n",
    "            for sender in veh_edge:\n",
    "                for receiver in veh_contra:\n",
    "                    #if not met yet or met long time ago:\n",
    "                    if ((not((sender, receiver) in meeting_times)) or\n",
    "                        meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                        mets.append(create_meeting_dict(sender, receiver, \"opposed\", contra_edge))\n",
    "                        mets.append(create_meeting_dict(receiver, sender, \"opposed\", edge)) #they meet vice-versa\n",
    "\n",
    "\n",
    "    return mets #vehicles at the same time, at the same place, not the 'ego' vehicle and not met recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_upon_meeting(senders_data, receiver_position, on_same_edge, meeting_time, seed, time_limit=TIME_LIMIT, ego_time=FALL_BACK_TIME):\n",
    "    send_data = senders_data[senders_data[\"seed\"] == seed]\n",
    "    send_data = send_data[send_data[\"time\"] <= meeting_time]\n",
    "    send_data = send_data[send_data[\"time\"] >= meeting_time-time_limit]\n",
    "    \n",
    "    if len(send_data)==0:\n",
    "        return None, None\n",
    "\n",
    "    #calculating the zopt solution:\n",
    "    probabilities = source_probs if on_same_edge else forward_probs\n",
    "    s_data, perf = zopt.calc_send_data(send_data, probabilities[str(edge_to_idx[receiver_position])], idx_to_edge,\n",
    "                                       receiver_position, meeting_time)\n",
    "    has_alters = True if (s_data is None) or (len(s_data) == 0) else False\n",
    "    s_data = pd.concat([s_data, send_data[send_data[\"time\"] >= meeting_time-ego_time]],\n",
    "                            ignore_index=True)\n",
    "      \n",
    "    if s_data is None:\n",
    "        return None, None\n",
    "    perf[\"has_no_zopt_data\"] = has_alters\n",
    "    return s_data.drop(columns=[\"receive_time\"]), perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_data(args):\n",
    "    sender, receiver, time, seed, vehicles_kb, receiver_position, on_same_edge = args\n",
    "\n",
    "    rec_dat, perf = collect_data_upon_meeting(vehicles_kb[sender], receiver_position,\n",
    "                                              on_same_edge, time, seed)\n",
    "    if rec_dat is None:\n",
    "        store_shared_data = {\n",
    "            \"sender\": sender,\n",
    "            \"receiver\": receiver,\n",
    "            \"time\": time,\n",
    "        }\n",
    "        updated_kb = vehicles_kb[receiver]\n",
    "        \n",
    "    else:     \n",
    "        received_data = rec_dat.copy()\n",
    "\n",
    "        #storing shared data:\n",
    "        store_shared_data = {\n",
    "            \"sender\": sender,\n",
    "            \"receiver\": receiver,\n",
    "            \"time\": time,\n",
    "            \"data\": received_data.to_json(),\n",
    "            \"performance\": perf\n",
    "        }\n",
    "\n",
    "        #fusing data into the receiver vehicle's dataset:\n",
    "        rec_t = [time]*len(received_data)\n",
    "        received_data[\"receive_time\"] = rec_t\n",
    "\n",
    "        updated_kb = pd.concat([vehicles_kb[receiver], received_data], ignore_index=True)\n",
    "        updated_kb = updated_kb.drop_duplicates(subset=\"hash\", ignore_index=True)\n",
    "\n",
    "    return store_shared_data, updated_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(zopt);\n",
    "\n",
    "def per_seed_script(seed):\n",
    "    ps_data = p_data[p_data[\"seed\"] == seed]\n",
    "    \n",
    "    meeting_times = {}\n",
    "    vehicles_kb = {}\n",
    "    store_sharing = []\n",
    "\n",
    "    for veh in test_vehicles:\n",
    "        vehicles_kb[veh] = ps_data[ps_data[\"veh_id\"] == veh].copy()\n",
    "\n",
    "    for t in trange(min(p_data[\"time\"]), max(p_data[\"time\"])):\n",
    "        meetings = collect_meeting_vehicles(m_data, t, seed, meeting_times)\n",
    "        for meet_map in meetings:\n",
    "            sender = meet_map[\"sender\"]\n",
    "            receiver = meet_map[\"receiver\"]\n",
    "            receiver_position = meet_map[\"receiver_position\"]\n",
    "            on_same_edge = meet_map[\"direction\"] == \"same\"\n",
    "\n",
    "            arguments = [sender, receiver, t, seed, vehicles_kb,\n",
    "                         receiver_position, on_same_edge]\n",
    "            meeting_times[(sender, receiver)] = t\n",
    "\n",
    "            new_store, updated_kb = receive_data(arguments)\n",
    "            vehicles_kb[receiver] = updated_kb\n",
    "            store_sharing.append(new_store)\n",
    "\n",
    "    for veh in vehicles_kb:\n",
    "        vehicles_kb[veh].to_csv(f\"08_shared_veh_data/zopt/{seed}/{veh}.csv\", index=False)\n",
    "    store_dict = {\n",
    "        \"shared_data\": store_sharing\n",
    "    }\n",
    "    with open(f\"08_shared_veh_data/zopt/{seed}/shared_data.json\", \"w\") as f:\n",
    "        json.dump(store_dict, f)\n",
    "\n",
    "with Pool(5) as ps:\n",
    "    ps.map(per_seed_script, SEEDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
