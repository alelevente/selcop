{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03023ba7-947d-4d26-b819-9231e964d663",
   "metadata": {},
   "source": [
    "# **Preparations for Meeting Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f8b3df-ed6a-44f1-aa89-bbf14362648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from multiprocessing.pool import Pool, ThreadPool\n",
    "from multiprocessing import Lock\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import copy\n",
    "\n",
    "import sumolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d6a16f-3e25-487d-9391-b1228fd5c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 1234, 1867, 613, 1001]\n",
    "TIME_LIMIT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87538e11-f9f5-4cbe-9cd4-8faae9c28498",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_ROOT = \"../../02_data/01_simulation_results/\"\n",
    "VEH_LIST_PATH = \"../../02_data/veh_list.json\"\n",
    "MEETING_PATH = \"../../02_data/03_meeting_data/\"\n",
    "MEETING_VEHICLES = \"../../02_data/meeting_vehicles\"\n",
    "EDGE_MAP_PATH = \"../../02_data/edge_maps.json\"\n",
    "NEIGHBORING_EDGES_FILE = \"../../02_data/neighboring_edges.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9f7cbd-f60f-4e09-8dfa-3fffc10dfcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading *test* vehicles:\n",
    "\n",
    "with open(VEH_LIST_PATH) as f:\n",
    "    veh_list  = json.load(f)\n",
    "\n",
    "test_vehicles = veh_list[\"test_vehs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28fef14-db48-4fbc-ad6b-1edec1739112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_commuters(veh_id):\n",
    "    if veh_id.startswith(\"carIn\"):\n",
    "        return veh_id.split(\":\")[0]\n",
    "    return veh_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eddb8b5-6701-4773-b841-4b820922c66a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Creating the combination dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60606357-4ed8-42b8-8290-9127e1805b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading parking simulation data and combine commuter vehicle ids:\n",
    "\n",
    "#data reading:\n",
    "p_data = pd.DataFrame()\n",
    "\n",
    "for s in SEEDS:\n",
    "    filename = f'{RESULTS_ROOT}/poccup_by_vehs_{s}.csv'\n",
    "    pf = pd.read_csv(filename)\n",
    "    pf[\"seed\"] = [s]*len(pf)\n",
    "    p_data = pd.concat([p_data, pf])\n",
    "\n",
    "#handling the commuters:\n",
    "p_data[\"veh_id\"] = p_data[\"veh_id\"].apply(combine_commuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe963f-5197-4657-a848-d9fa064c27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating key for the measurements:\n",
    "\n",
    "def calculate_hash(datarow):\n",
    "    key = r.parking_id + str(r.time) + str(r.occupancy) + str(r.seed)\n",
    "    return hash(key)\n",
    "\n",
    "\n",
    "hashes = []\n",
    "for i,r in p_data.iterrows():\n",
    "    hashes.append(calculate_hash(r))\n",
    "p_data[\"hash\"] = hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ecb8c-e071-4b9a-b7a0-85a1bbdaaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data.to_csv(f\"{MEETING_PATH}/combined_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab9ffd-e0c2-43a1-917a-2978324a495c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Collecting neighboring edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7331938-13f1-48c8-b753-9baf9ed15109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input:\n",
    "NETWORK_FILE = \"../../01_simulation/02_scenario/rand_grid.net.xml\"\n",
    "#output:\n",
    "NEIGHBORING_EDGE_FILE = \"../../02_data/neighboring_edges.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36a1bf46-e3e4-4281-9973-2d14c5e7528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opposed(edge_name):\n",
    "    opposed = \"\"\n",
    "    if edge_name.startswith(\"-\"):\n",
    "        opposed = edge_name.split(\"-\")[-1]\n",
    "    else:\n",
    "        opposed = f\"-{edge_name}\"\n",
    "    return opposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97f07b74-1e50-4293-9a5e-5e2e6404792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(NETWORK_FILE)\n",
    "edges = net.getEdges()\n",
    "neighbors = {}\n",
    "\n",
    "#collecting neighbors:\n",
    "for edge in edges:\n",
    "    edge_id = edge.getID()\n",
    "    neighbors[edge_id] = []\n",
    "    for inc in edge.getIncoming():\n",
    "        neighbors[edge_id].append(inc.getID())\n",
    "        neighbors[edge_id].append(get_opposed(inc.getID()))\n",
    "    for outg in edge.getOutgoing():\n",
    "        neighbors[edge_id].append(outg.getID())\n",
    "        neighbors[edge_id].append(get_opposed(outg.getID()))\n",
    "        \n",
    "#a couple of edges are connected to each other,\n",
    "#therefore, we have to remove them from it neighbors:\n",
    "for edge in neighbors:\n",
    "    if edge in neighbors[edge]:\n",
    "        neighbors[edge].remove(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38ce6c6a-88e7-436f-a5a2-1533d96cc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NEIGHBORING_EDGE_FILE, \"w\") as f:\n",
    "    json.dump(neighbors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93973ee6-71ed-468b-9d27-f6732f62c7c4",
   "metadata": {},
   "source": [
    "## Collecting meeting vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b0b261-670d-429c-80af-0fcb176b3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading *test* vehicles:\n",
    "with open(VEH_LIST_PATH) as f:\n",
    "    veh_list  = json.load(f)\n",
    "\n",
    "test_vehicles = veh_list[\"test_vehs\"]\n",
    "\n",
    "with open(EDGE_MAP_PATH) as f:\n",
    "    edge_maps = json.load(f)\n",
    "\n",
    "edge_to_idx = edge_maps[\"edge_to_idx\"]\n",
    "\n",
    "with open(NEIGHBORING_EDGES_FILE) as f:\n",
    "    neighbors = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585bf7ce-91fd-4d96-848f-a25d959a4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_commuters(veh_id):\n",
    "    if veh_id.startswith(\"carIn\"):\n",
    "        return veh_id.split(\":\")[0]\n",
    "    return veh_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182c3579-6dc3-43c9-88fe-12134e64936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading moving simulation data:\n",
    "\n",
    "m_data = pd.DataFrame()\n",
    "for s in SEEDS:\n",
    "    filename = f\"{RESULTS_ROOT}/vehicle_positions_{s}.csv\"\n",
    "    mf = pd.read_csv(filename)\n",
    "    mf[\"seed\"] = [s]*len(mf)\n",
    "    m_data = pd.concat([m_data, mf])\n",
    "\n",
    "m_data[\"veh_id\"] = m_data[\"veh_id\"].apply(combine_commuters)\n",
    "m_data = m_data[m_data[\"veh_id\"].isin(test_vehicles)]\n",
    "m_data = m_data[~m_data[\"edge\"].str.startswith(\":\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8db5e-3d3e-48bf-99bf-0b9ef4aea968",
   "metadata": {},
   "source": [
    "### Meeting definition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d8b8bb-c555-4164-b6a2-027d319e42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_meeting_vehicles_narrow(m_data, meeting_time, meeting_times, meeting_time_gap=TIME_LIMIT):\n",
    "    #collecting recently met vehicles:\n",
    "    \n",
    "    meetings = m_data[m_data[\"time\"] == meeting_time]\n",
    "\n",
    "    mets = []\n",
    "\n",
    "    #same edges:\n",
    "    for edge in edge_to_idx:\n",
    "        vehs = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "        for i in range(len(vehs)):\n",
    "            for j in range(i+1, len(vehs)):\n",
    "                sender = vehs[i]\n",
    "                receiver = vehs[j]\n",
    "                #if not met yet or met long time ago:\n",
    "                if ((not((sender, receiver) in meeting_times)) or\n",
    "                    meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                    mets.append((sender, receiver))\n",
    "                    mets.append((receiver, sender)) #they meet vice-versa\n",
    "\n",
    "    #opposed edges:\n",
    "    for edge in edge_to_idx:\n",
    "        #only \"reversed\" edges are processed, to avoid duplicated meetings:\n",
    "        if edge.startswith(\"-\"):\n",
    "            veh_edge = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "            contra_edge = edge.split(\"-\")[1]\n",
    "            veh_contra = meetings[meetings[\"edge\"] == contra_edge][\"veh_id\"].unique()\n",
    "            for sender in veh_edge:\n",
    "                for receiver in veh_contra:\n",
    "                    #if not met yet or met long time ago:\n",
    "                    if ((not((sender, receiver) in meeting_times)) or\n",
    "                        meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                        mets.append((sender, receiver))\n",
    "                        mets.append((receiver, sender)) #they meet vice-versa\n",
    "\n",
    "\n",
    "    return mets #vehicles at the same time, at the same place, not the 'ego' vehicle and not met recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bfd663e-f3fd-4a9d-9f3a-a645c785609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_meeting_vehicles_broad(m_data, meeting_time, meeting_times, meeting_time_gap=TIME_LIMIT,\n",
    "                                   neighboring_edges = neighbors):\n",
    "    #collecting recently met vehicles:\n",
    "    \n",
    "    meetings = m_data[m_data[\"time\"] == meeting_time]\n",
    "\n",
    "    mets = []\n",
    "        \n",
    "    for edge in edge_to_idx:\n",
    "        veh_edge = meetings[meetings[\"edge\"] == edge][\"veh_id\"].unique()\n",
    "        #same edge:\n",
    "        for i in range(len(veh_edge)):\n",
    "            for j in range(i+1, len(veh_edge)):\n",
    "                sender = veh_edge[i]\n",
    "                receiver = veh_edge[j]\n",
    "                #if not met yet or met long time ago:\n",
    "                if ((not((sender, receiver) in meeting_times)) or\n",
    "                    meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                    mets.append((sender, receiver))\n",
    "                    mets.append((receiver, sender)) #they meet vice-versa\n",
    "        \n",
    "        #neighboring edges:\n",
    "        veh_contra = meetings[meetings[\"edge\"].isin(neighboring_edges[edge])][\"veh_id\"].unique()\n",
    "        for sender in veh_edge:\n",
    "            for receiver in veh_contra:\n",
    "                #if not met yet or met long time ago:\n",
    "                if ((not((sender, receiver) in meeting_times)) or\n",
    "                    meeting_time - meeting_times[(sender, receiver)] > meeting_time_gap):\n",
    "                    mets.append((sender, receiver)) #vice-versa meetings are coming from the other neighboring\n",
    "\n",
    "\n",
    "    return mets #vehicles at the same time, at the same place, not the 'ego' vehicle and not met recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8214b22f-f7fa-469f-a269-7d16d3509cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the collector scripts:\n",
    "def collector_script(args):\n",
    "    seed, collect_method, meas_name = args\n",
    "    meeting_times = {}\n",
    "    meeting_collection = {}\n",
    "\n",
    "    m_data_filt = m_data[m_data[\"seed\"] == seed]\n",
    "    m_data_hour = m_data_filt[m_data_filt[\"time\"] <= min(m_data_filt[\"time\"])+6*60*60]\n",
    "    \n",
    "    for t in range(int(min(m_data[\"time\"])), int(max(m_data[\"time\"]))):\n",
    "        if t%(6*60*60) == 0:\n",
    "            m_data_hour = m_data_filt[(m_data_filt[\"time\"] >= t) &\n",
    "                            (m_data_filt[\"time\"] < t+6*60*60)]\n",
    "        #m_data_filt = m_data_filt[m_data_filt[\"time\"] >= t]\n",
    "        meetings = collect_method(m_data_hour, t, meeting_times)\n",
    "        meeting_collection[t] = meetings\n",
    "        for sender, receiver in meetings:\n",
    "            meeting_times[(sender, receiver)] = t\n",
    "\n",
    "    with open(f\"{MEETING_VEHICLES}_{meas_name}_{seed}.json\", \"w\") as f:\n",
    "        json.dump(meeting_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbff39-bcc0-4db4-831c-1ff77b868e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(5) as ps:\n",
    "    ps.map(collector_script, zip(SEEDS, [collect_meeting_vehicles_broad]*5, [\"broad\"]*5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
